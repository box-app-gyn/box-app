# CERRADÃ˜ AI Backend

Backend para IA de atendimento do CERRADÃ˜ INTERBOX 2025.

## ğŸš€ Features

- **Chat com Vertex AI** - IntegraÃ§Ã£o com Google Vertex AI
- **Streaming de respostas** - Respostas em tempo real
- **SessÃµes persistentes** - HistÃ³rico de conversas
- **Rate limiting** - ProteÃ§Ã£o contra spam
- **WebSocket** - Chat em tempo real
- **Analytics** - MÃ©tricas de uso
- **Logs detalhados** - Monitoramento completo

## ğŸ“‹ PrÃ©-requisitos

- Node.js 18+
- MongoDB Atlas (gratuito)
- Google Cloud Project com Vertex AI habilitado
- Service Account Key do Google Cloud

## ğŸ› ï¸ Setup

### 1. Clone e instale dependÃªncias
```bash
cd backend-example
npm install
```

### 2. Configure as variÃ¡veis de ambiente
```bash
cp env.example .env
# Edite o arquivo .env com suas configuraÃ§Ãµes
```

### 3. Configure o Google Cloud
```bash
# Baixe sua service account key
# Coloque em ./vertex-ai-sa-key.json
```

### 4. Configure o MongoDB
- Crie uma conta no MongoDB Atlas
- Crie um cluster gratuito
- Copie a URI de conexÃ£o
- Adicione no .env

### 5. Teste a conexÃ£o
```bash
npm run dev
# Acesse http://localhost:3001/health
```

## ğŸš€ Deploy

### Railway (Recomendado)
```bash
# Instale Railway CLI
npm i -g @railway/cli

# Login e deploy
railway login
railway init
railway up
```

### Render
```bash
# Conecte seu repositÃ³rio no Render
# Configure as variÃ¡veis de ambiente
# Deploy automÃ¡tico
```

### Vercel
```bash
# Instale Vercel CLI
npm i -g vercel

# Deploy
vercel
```

## ğŸ“¡ APIs

### Chat
- `POST /api/chat/message` - Enviar mensagem
- `POST /api/chat/stream` - Chat com streaming
- `GET /api/chat/history/:sessionId` - HistÃ³rico
- `POST /api/chat/session` - Criar sessÃ£o
- `DELETE /api/chat/session/:sessionId` - Encerrar sessÃ£o
- `POST /api/chat/feedback` - Avaliar resposta

### Auth
- `POST /api/auth/login` - Login
- `POST /api/auth/register` - Registro
- `GET /api/auth/me` - Perfil do usuÃ¡rio

### Analytics
- `GET /api/analytics/usage` - MÃ©tricas de uso
- `GET /api/analytics/sessions` - SessÃµes ativas

## ğŸ”§ ConfiguraÃ§Ã£o

### Vertex AI
```javascript
// Configurar modelo
const model = 'gemini-1.5-flash-001';
const temperature = 0.7;
const maxTokens = 1000;
```

### Rate Limiting
```javascript
// Limites por IP
const windowMs = 15 * 60 * 1000; // 15 minutos
const maxRequests = 100; // 100 requests por janela
```

### Logging
```javascript
// NÃ­veis de log
LOG_LEVEL=info // debug, info, warn, error
```

## ğŸ“Š Monitoramento

### Health Check
```bash
curl https://your-backend.railway.app/health
```

### Logs
```bash
# Railway
railway logs

# Render
# DisponÃ­vel no dashboard
```

## ğŸ”’ SeguranÃ§a

- **Helmet** - Headers de seguranÃ§a
- **CORS** - Configurado para domÃ­nio especÃ­fico
- **Rate Limiting** - ProteÃ§Ã£o contra spam
- **JWT** - AutenticaÃ§Ã£o segura
- **Input Validation** - ValidaÃ§Ã£o de dados

## ğŸ§ª Testes

```bash
npm test
```

## ğŸ“ˆ Performance

- **Caching** - SessÃµes em memÃ³ria
- **Connection Pooling** - MongoDB otimizado
- **Streaming** - Respostas em tempo real
- **Compression** - Gzip habilitado

## ğŸ”„ IntegraÃ§Ã£o com Frontend

```javascript
// Exemplo de uso no frontend
const response = await fetch('https://your-backend.railway.app/api/chat/message', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${token}`
  },
  body: JSON.stringify({
    message: 'OlÃ¡, como faÃ§o para me inscrever?',
    sessionId: 'session-123'
  })
});

const data = await response.json();
console.log(data.response);
```

## ğŸ†˜ Suporte

Para dÃºvidas ou problemas:
- Abra uma issue no repositÃ³rio
- Consulte os logs do servidor
- Verifique a documentaÃ§Ã£o da API

## ğŸ“„ LicenÃ§a

MIT License 